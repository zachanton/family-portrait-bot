# docker-compose.yml
services:
  postgres:
    image: postgres:16-alpine
    container_name: postgres
    environment:
      # Используем новые имена переменных
      POSTGRES_USER: ${DB__PG_USER}
      POSTGRES_PASSWORD: ${DB__PG_PASSWORD}
      POSTGRES_DB: ${DB__PG_DATABASE}
    ports:
      - "127.0.0.1:${DB__PG_PORT}:${DB__PG_PORT}"
    volumes:
      - pg_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB__PG_USER} -d ${DB__PG_DATABASE}"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - app_network
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      # Используем новые имена переменных
      - "${REDIS__PORT}:${REDIS__PORT}"
    volumes:
      - redis_data:/data
    # Используем новые имена переменных
    command: redis-server --requirepass ${REDIS__PASSWORD}
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS__PASSWORD}", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - app_network
    restart: unless-stopped

  bento-local-ml:
    image: local_ml_service:latest
    container_name: bento-local-ml
    ipc: host
    environment:
          # Общие
          - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
          - HF_TOKEN=${HF_TOKEN}
          # Переменные для FLUX (будут использованы, если провайдер=flux)
          - MODEL_ID=${FLUX__MODEL_ID}
          - GGUF_CKPT_PATH=${FLUX__GGUF_CKPT_PATH}
          # Переменные для QWEN (будут использованы, если провайдер=qwen)
          - QWEN_MODEL_ID=${QWEN__MODEL_ID}
          - QWEN_GGUF_CKPT_PATH=${QWEN__GGUF_CKPT_PATH}
    volumes:
          - ./models:/home/bentoml/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
        limits:
          memory: 50G
    networks:
      - app_network
    restart: unless-stopped
    init: true
    ports:
      - "3000:3000"
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://127.0.0.1:3000/generate || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s

  aiogram-bot:
    build:
      context: .
      dockerfile: Dockerfile.bot
    container_name: aiogram-bot
    depends_on:
      postgres: { condition: service_healthy }
      redis: { condition: service_healthy }
      bento-local-ml: { condition: service_started }
    ports:
      - "127.0.0.1:8081:8081"
      - "127.0.0.1:8000:8000"
    networks:
      - app_network
    restart: unless-stopped
    env_file: .env
    volumes:
      # Mounts the local source code into the container for live reloading
      - ./aiogram_bot_template:/app/aiogram_bot_template

volumes:
  pg_data:
  redis_data:

networks:
  app_network:
    driver: bridge
