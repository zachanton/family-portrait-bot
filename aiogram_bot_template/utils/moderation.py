# aiogram_bot_template/utils/moderation.py
import logging
from openai import AsyncOpenAI

openai_client = AsyncOpenAI()
logger = logging.getLogger(__name__)


async def _moderation_flagged(inputs: list[dict]) -> bool:
    """
    Returns True if the OpenAI moderation endpoint flags the content.

    Returns:
        bool: True if content is flagged as unsafe, otherwise False.
    """
    try:
        resp = await openai_client.moderations.create(
            model="text-moderation-latest", input=inputs, timeout=15
        )

        result = resp.results[0]
        flagged = bool(result.flagged)

        if flagged:
            logger.warning(
                "ðŸš¨ Moderation flagged content",
                scores=result.category_scores.dict(),
                categories=result.categories.dict(),
            )

        return flagged  # noqa: TRY300

    except Exception:
        logger.exception("OpenAI moderation call failed")
        # Ð’ ÑÐ»ÑƒÑ‡Ð°Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ API, Ð´Ð»Ñ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸ ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ Ð½ÐµÐ±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ñ‹Ð¼.
        return True


async def is_safe_prompt(prompt: str) -> bool:
    """
    Returns True if the text prompt is considered safe by the moderation API.

    Returns:
        bool: True if prompt is safe, False otherwise.
    """
    # OpenAI API Ð¾Ð¶Ð¸Ð´Ð°ÐµÑ‚ ÑÑ‚Ñ€Ð¾ÐºÑƒ Ð¸Ð»Ð¸ Ð¼Ð°ÑÑÐ¸Ð² ÑÑ‚Ñ€Ð¾Ðº, Ð° Ð½Ðµ ÑÐ»Ð¾Ð¶Ð½ÑƒÑŽ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ.
    # Ð”Ð»Ñ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð° Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‚ÑŒ ÑÐ°Ð¼Ñƒ ÑÑ‚Ñ€Ð¾ÐºÑƒ.
    return not await _moderation_flagged([prompt])


async def is_nsfw_image(image_url: str, *, prompt: str | None = None) -> bool:
    """
    Returns True if the image (and optionally text) violates NSFW rules.
    This function is not currently used but is ready for future implementation.

    Returns:
        bool: True if NSFW is detected, otherwise False.
    """
    inputs = [image_url]
    if prompt:
        inputs.append(prompt)

    return await _moderation_flagged(inputs)
